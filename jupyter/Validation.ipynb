{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from awsglue.transforms import Map, DropFields, ApplyMapping\n",
    "\n",
    "sc = SparkContext()\n",
    "context = GlueContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"s3://network.cubo.datalake/airtable/raw/prod/\"\n",
    "path = path + \"2022-12-29-15-21-18/data/\"\n",
    "path = path + \"Selo Cubo Startups/Selo Cubo 2023/üìù Respostas Selo Cubo/\"\n",
    "print(path)\n",
    "dataframe = context.create_dynamic_frame.from_options(\n",
    "                connection_type='s3',\n",
    "                connection_options={\n",
    "                    'paths': [path],\n",
    "                    'recurse': True\n",
    "                },\n",
    "                format='json'\n",
    "            )\n",
    "dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|faturamento_2022       |\n",
      "+-----------------------+\n",
      "|{null, 8500000, null}  |\n",
      "|{null, 34000000, null} |\n",
      "|{null, 2400000, null}  |\n",
      "|{null, 2500000, null}  |\n",
      "|{null, 8550000, null}  |\n",
      "|{null, 1068732, null}  |\n",
      "|{null, 1920000, null}  |\n",
      "|{null, 270000, null}   |\n",
      "|{null, 340000, null}   |\n",
      "|{null, 1100000, null}  |\n",
      "|{null, 2000000, null}  |\n",
      "|{null, 4300000, null}  |\n",
      "|{null, 5000000, null}  |\n",
      "|{null, 10000000, null} |\n",
      "|{null, 3500000, null}  |\n",
      "|{null, 2400000, null}  |\n",
      "|{null, 1850000, null}  |\n",
      "|{null, 1050000, null}  |\n",
      "|{null, 4300000, null}  |\n",
      "|{null, 430000000, null}|\n",
      "+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def recItem(ref):\n",
    "    ref[\"faturamento_2022\"] = 1\n",
    "    return ref\n",
    "\n",
    "newDf = dataframe.apply_mapping([(\n",
    "    \"fields.Faturamento 2022\", \"faturamento_2022\"\n",
    ")])\n",
    "newDf2 = newDf.unnest()\n",
    "newDf2.toDF().show(truncate=False)\n",
    "# newDf1 = newDf.toDF()\n",
    "\n",
    "# from pyspark.sql.functions import col\n",
    "# # newDf1 = dataframe.toDF()\n",
    "# # newDf1.filter(col(\"fields.Faturamento 2022\").isNotNull()).show()\n",
    "# # newDf2 = newDf1.filter(col(\"faturamento_2022\").isNotNull())\n",
    "# # newDf2.printSchema()\n",
    "# newDf2 = newDf1\n",
    "# newDf2.printSchema()\n",
    "# newDf2.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
